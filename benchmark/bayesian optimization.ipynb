{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f24ad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d4638c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_chosen_labelled_datas_PCA(X_train,idx_lb,y_train,b_idxs,rd,h):\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    transformed = pca.fit_transform(X=X_train)\n",
    "    x_component = transformed[:, 0]\n",
    "    \n",
    "    plt.figure(figsize=[9,6])\n",
    "    plt.scatter(transformed[:, 0][~idx_lb],transformed[:, 1][~idx_lb],label=\"unlabelled points\",c=\"brown\")\n",
    "    plt.scatter(transformed[:, 0][idx_lb],transformed[:, 1][idx_lb],label=\"labelled points\")\n",
    "    plt.scatter(transformed[:, 0][b_idxs],transformed[:, 1][b_idxs],label=\"new points added\",c=\"yellow\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"points selected after {rd} rounds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc98161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_173096\\926296027.py:27: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  maintenance=pd.read_csv('C:/Users/matth/jupyter codes/Recherche/datasets/conditions_based_maintenance/data.txt',sep=\"   \", header=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1202, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = datasets.load_boston()\n",
    "df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "df[\"target\"]=boston.target\n",
    "y_boston=df.target\n",
    "X_boston=df.drop(\"target\",axis=1)\n",
    "#scaler = RobustScaler()\n",
    "#X_boston=pd.DataFrame(scaler.fit_transform(X_boston)).set_axis(X_boston.columns, axis=1)\n",
    "y_boston=torch.Tensor(y_boston).view(len(y_boston),1).float()\n",
    "X_boston=torch.Tensor(X_boston.values).float()\n",
    "\n",
    "\n",
    "columns_names=[\"Frequency\",\"Angle of attack\",\"Chord length\",\"Free-stream velocity\",\"Suction side displacement thickness\",\"sound pressure level\"]\n",
    "airfoil=pd.read_csv('C:/Users/matth/jupyter codes/Recherche/datasets/airfoil_self_noise.dat',sep='\\t',names=columns_names)\n",
    "y_airfoil=airfoil[\"sound pressure level\"]\n",
    "X_airfoil=airfoil.drop(\"sound pressure level\",axis=1)\n",
    "y_airfoil=torch.Tensor(y_airfoil).view(len(y_airfoil),1).float()\n",
    "X_airfoil=torch.Tensor(X_airfoil.values).float()\n",
    "\n",
    "\n",
    "energy=pd.read_csv('C:/Users/matth/jupyter codes/Recherche/datasets/energy efficiency.csv')\n",
    "y_energy=energy[\"Y2\"]\n",
    "X_energy=energy.drop([\"Y2\",\"Y1\"],axis=1)\n",
    "y_energy=torch.Tensor(y_energy).view(len(y_energy),1).float()\n",
    "X_energy=torch.Tensor(X_energy.values).float()\n",
    "\n",
    "\n",
    "maintenance=pd.read_csv('C:/Users/matth/jupyter codes/Recherche/datasets/conditions_based_maintenance/data.txt',sep=\"   \", header=None)\n",
    "y_maintenance=maintenance[17]\n",
    "X_maintenance=maintenance.drop([16,17],axis=1)\n",
    "y_maintenance=torch.Tensor(y_maintenance).view(len(y_maintenance),1).float()\n",
    "X_maintenance=torch.Tensor(X_maintenance.values).float()\n",
    "\n",
    "\n",
    "proportion=0.2\n",
    "scaler = MinMaxScaler()\n",
    "X=X_airfoil\n",
    "y=y_airfoil\n",
    "\n",
    "X=torch.Tensor(scaler.fit_transform(X))\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=proportion)\n",
    "\n",
    "#generating testset\n",
    "\n",
    "#For Boston\n",
    "#scaler_test = RobustScaler()\n",
    "#y_train=torch.Tensor(scaler_test.fit_transform(y_train))\n",
    "\n",
    "#taking limited number of datas to make the query process run faster\n",
    "#X_train=X_train[:100]\n",
    "#y_train=y_train[:100]\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b6283f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pi(mu, std, y_max, beta):\n",
    "    Z = (mu - y_max - beta) / std\n",
    "    return norm.cdf(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "545aeb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================Round 1===============\n",
      "24 1178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_173096\\1425837751.py:43: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  reg.fit(X_train[idx_lb_train],y_train[idx_lb_train])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "predict() got an unexpected keyword argument 'return_std'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_173096\\1425837751.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;31m#print(std)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;31m#print(np.sort(std))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_std\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx_ulb_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_std\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m             \u001b[0my_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx_lb_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mpi_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_std\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: predict() got an unexpected keyword argument 'return_std'"
     ]
    }
   ],
   "source": [
    "nb_initial_labelled_datas=int(0.02*X_train.shape[0])\n",
    "n_query_each_round=int(0.02*X_train.shape[0])#int(0.02*X_train.shape[0])\n",
    "num_round=int(np.ceil((len(y_train)-nb_initial_labelled_datas)/n_query_each_round))\n",
    "dim_input=13\n",
    "total_epoch_h=100\n",
    "batch_size_train=len(X_train)\n",
    "lr_h=0.001\n",
    "beta=10\n",
    "\n",
    "liste_results=[]\n",
    "for m in range(5):\n",
    "\n",
    "    n_pool = len(y_train)\n",
    "    n_test = len(y_test)\n",
    "    idxs_lb = np.zeros(n_pool, dtype=bool)\n",
    "    idxs_tmp = np.arange(n_pool)\n",
    "    np.random.shuffle(idxs_tmp)\n",
    "    idxs_lb[idxs_tmp[:nb_initial_labelled_datas]] = True\n",
    "\n",
    "\n",
    "    config_NN=[2,16,32]\n",
    "\n",
    "    RMSE_list=[]\n",
    "    MAPE_list=[]\n",
    "    MAE_list=[]\n",
    "\n",
    "\n",
    "        # Gaussian process regression\n",
    "    kernel = RBF(length_scale=0.1, length_scale_bounds=(1e-8, 1e8)) \\\n",
    "             + WhiteKernel()\n",
    "\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel,n_restarts_optimizer=5)\n",
    "\n",
    "    for rd in range(1,num_round+1):\n",
    "\n",
    "        print('\\n================Round {:d}==============='.format(rd))\n",
    "\n",
    "        if rd==num_round:\n",
    "                last_query=True\n",
    "\n",
    "        idx_lb_train = np.arange(n_pool)[idxs_lb]\n",
    "        idx_ulb_train = np.arange(n_pool)[~idxs_lb]\n",
    "        print(len(X_train[idx_lb_train]),len(X_train[idx_ulb_train]))\n",
    "        #print(X_train[idx_lb_train])\n",
    "        #print(len(trainloader_labelled))\n",
    "\n",
    "        gpr.fit(X_train[idx_lb_train],y_train[idx_lb_train])\n",
    "\n",
    "        if rd==num_round:\n",
    "            print(\"hey\")\n",
    "            idxs_lb[:]= True\n",
    "        else:\n",
    "\n",
    "            #print(std)\n",
    "            #print(np.sort(std))\n",
    "            y_pred, y_std = gpr.predict(X_train[idx_ulb_train], return_std=True)\n",
    "            y_max = np.max(y_train[idx_lb_train])\n",
    "            pi_values = pi(y_pred, y_std, y_max, beta)\n",
    "                                        \n",
    "            query_idx= np.argsort(pi_values)[-n_query_each_round:]\n",
    "            #print(query_idx)\n",
    "            print(idx_ulb_train[query_idx])\n",
    "            idxs_lb[idx_ulb_train[query_idx]] = True\n",
    "            display_chosen_labelled_datas_PCA(X_train,idxs_lb,y_train,idx_ulb_train[query_idx],rd,h)\n",
    "\n",
    "        y_pred=h(X_test)\n",
    "        RMSE_list.append(np.sqrt(mean_squared_error(y_pred.detach().numpy(),y_test)))\n",
    "        MAPE_list.append(mean_absolute_percentage_error(y_pred.detach().numpy(),y_test))\n",
    "        MAE_list.append(mean_absolute_error(y_pred.detach().numpy(),y_test))\n",
    "\n",
    "    print('\\n================Final training===============')\n",
    "\n",
    "    idx_lb_train = np.arange(n_pool)[idxs_lb]\n",
    "    idx_ulb_train = np.arange(n_pool)[~idxs_lb]\n",
    "    trainset_labelled=myData(X_train[idx_lb_train],y_train[idx_lb_train])\n",
    "    trainloader_labelled= DataLoader(trainset_labelled,shuffle=True,batch_size=batch_size_train)\n",
    "\n",
    "    for epoch in range(total_epoch_h):\n",
    "\n",
    "            for i,data in enumerate(trainloader_labelled,0):\n",
    "                label_x, label_y=data\n",
    "                opti_h.zero_grad() \n",
    "                lb_out = h(label_x)\n",
    "                #print(label_x)\n",
    "                h_descent=torch.mean((lb_out-label_y)**2)\n",
    "                h_descent.backward()\n",
    "                opti_h.step()\n",
    "\n",
    "    y_pred=h(X_test)\n",
    "    RMSE_list.append(np.sqrt(mean_squared_error(y_pred.detach().numpy(),y_test)))\n",
    "    MAPE_list.append(mean_absolute_percentage_error(y_pred.detach().numpy(),y_test))\n",
    "    MAE_list.append(mean_absolute_error(y_pred.detach().numpy(),y_test))\n",
    "    liste_results.append([MAE_list,MAPE_list,RMSE_list])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
